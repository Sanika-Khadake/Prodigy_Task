{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QFSVsU7-f2J"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"leapgestrecog/leapGestRecog\""
      ],
      "metadata": {
        "id": "l5vOC_Fl-xme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = (64, 64)  # Image resizing dimensions\n",
        "categories = os.listdir(data_dir)  # List of gesture categories\n",
        "\n",
        "data = []\n",
        "labels = []"
      ],
      "metadata": {
        "id": "FhZweXBQ-yaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading images...\")\n",
        "for category in categories:\n",
        "    category_path = os.path.join(data_dir, category)\n",
        "    label = categories.index(category)\n",
        "\n",
        "    for img_name in os.listdir(category_path):\n",
        "        try:\n",
        "            img_path = os.path.join(category_path, img_name)\n",
        "            img = load_img(img_path, target_size=img_size, color_mode='grayscale')\n",
        "            img_array = img_to_array(img)\n",
        "            data.append(img_array)\n",
        "            labels.append(label)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {img_path}: {e}\")"
      ],
      "metadata": {
        "id": "fq-l4LUk-zXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data, dtype='float32') / 255.0  # Normalize pixel values to [0, 1]\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "06mHAd20-0JV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "Aq2xJ2t7-3TJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"leapGestRecog\""
      ],
      "metadata": {
        "id": "eBGlOnQV_3wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = (64, 64)"
      ],
      "metadata": {
        "id": "p4htsmiz_4Vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "labels = []"
      ],
      "metadata": {
        "id": "BkI6km5g_419"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading images...\")\n",
        "for folder in os.listdir(data_dir):\n",
        "    folder_path = os.path.join(data_dir, folder)\n",
        "    for img_name in os.listdir(folder_path):\n",
        "        try:\n",
        "            img_path = os.path.join(folder_path, img_name)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            img = cv2.resize(img, img_size)\n",
        "            data.append(img)\n",
        "            labels.append(folder)  # Folder name represents the gesture label\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {img_path}: {e}\")"
      ],
      "metadata": {
        "id": "TwBj4twA_5hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data, dtype='float32') / 255.0  # Normalize\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "Yjgc-_y1_6LX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.reshape(data.shape[0], img_size[0], img_size[1], 1)  # Add channel dimension"
      ],
      "metadata": {
        "id": "tLFyKyBY_6uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_binarizer = LabelBinarizer()\n",
        "labels = label_binarizer.fit_transform(labels)"
      ],
      "metadata": {
        "id": "MssJVZ04_7OU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "x1OBfv9V_71S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_size[0], img_size[1], 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(labels.shape[1], activation='softmax')  # Output layer for classification\n",
        "])\n"
      ],
      "metadata": {
        "id": "BM86O7oU_8WS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "NPL2yl0t_86h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training model...\")\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=32, verbose=1)"
      ],
      "metadata": {
        "id": "J4vIpKj1_9Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating model...\")\n",
        "eval_result = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {eval_result[0]:.4f}, Test Accuracy: {eval_result[1] * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "NzllDGBu_-Cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"hand_gesture_recognition_model.h5\")\n",
        "print(\"Model saved as 'hand_gesture_recognition_model.h5'\")"
      ],
      "metadata": {
        "id": "r4r71kkIA36b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "BtQvfD0KA6v1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))"
      ],
      "metadata": {
        "id": "Dl5CG_vrA7KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "j93EFXJKA8bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "7JjA2R7CA9QR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.show()"
      ],
      "metadata": {
        "id": "O0_4SLJzA9xl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}